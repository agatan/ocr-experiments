{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled0.ipynb",
      "version": "0.3.2",
      "views": {},
      "default_view": {},
      "provenance": [],
      "private_outputs": true,
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "P36apsD_enwc",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "!pip3 install http://download.pytorch.org/whl/cu80/torch-0.3.0.post4-cp36-cp36m-linux_x86_64.whl \n",
        "!pip3 install torchvision\n",
        "# !pip3 install --no-cache-dir -I pillow\n",
        "!git clone https://github.com/SeanNaren/warp-ctc.git\n",
        "!apt install cmake\n",
        "!cd warp-ctc && mkdir build; cd build && cmake .. && make\n",
        "!cd warp-ctc/pytorch_binding && python setup.py install"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "zLowm-JK9vxZ",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "import os.path\n",
        "\n",
        "if not os.path.exists('train'):\n",
        "    files.upload()\n",
        "    !tar xzvf train.tar.gz\n",
        "    \n",
        "if not os.path.exists('test'):\n",
        "    files.upload()\n",
        "    !tar xzvf test.tar.gz"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "4Ak4yv3E_CXj",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "import math\n",
        "import torch\n",
        "\n",
        "\n",
        "def meshgrid(x, y):\n",
        "    a = torch.arange(0, x)\n",
        "    b = torch.arange(0, y)\n",
        "    xx = a.repeat(y).view(-1, 1)\n",
        "    yy = b.view(-1, 1).repeat(1, x).view(-1, 1)\n",
        "    return torch.cat([xx, yy], 1)\n",
        "\n",
        "\n",
        "def xywh2xyxy(boxes):\n",
        "    xy = boxes[..., :2]\n",
        "    wh = boxes[..., 2:]\n",
        "    return torch.cat([xy - wh / 2, xy + wh / 2], -1)\n",
        "\n",
        "\n",
        "def xyxy2xywh(boxes):\n",
        "    xymin = boxes[:, :2]\n",
        "    xymax = boxes[:, 2:]\n",
        "    return torch.cat([(xymin + xymax) / 2, xymax - xymin + 1], 1)\n",
        "\n",
        "\n",
        "def box_iou(box1, box2):\n",
        "    lt = torch.max(box1[..., None, :2], box2[:, :2])  # N, M, 2\n",
        "    rb = torch.min(box1[..., None, 2:], box2[:, 2:])  # N, M, 2\n",
        "\n",
        "    wh = (rb - lt + 1).clamp(min=0)\n",
        "    inter = wh[:, :, 0] * wh[:, :, 1]  # N, M\n",
        "    area1 = (box1[..., 2] - box1[..., 0] + 1) * (box1[..., 3] - box1[..., 1] + 1)\n",
        "    area2 = (box2[..., 2] - box2[..., 0] + 1) * (box2[..., 3] - box2[..., 1] + 1)\n",
        "    iou = inter / (area1[:, None] + area2 - inter)\n",
        "    return iou\n",
        "\n",
        "\n",
        "def box_nms(bboxes, scores, thres=0.5):\n",
        "    x1 = bboxes[:, 0]\n",
        "    y1 = bboxes[:, 1]\n",
        "    x2 = bboxes[:, 2]\n",
        "    y2 = bboxes[:, 3]\n",
        "\n",
        "    areas = (x2 - x1 + 1) * (y2 - y1 + 1)\n",
        "    _, order = scores.sort(0, descending=True)\n",
        "\n",
        "    keep = []\n",
        "    while order.numel() > 0:\n",
        "        i = order[0]\n",
        "        keep.append(i)\n",
        "        if order.numel() == 1:\n",
        "            break\n",
        "        xx1 = x1[order[1:]].clamp(min=x1[i])\n",
        "        yy1 = y1[order[1:]].clamp(min=y1[i])\n",
        "        xx2 = x2[order[1:]].clamp(max=x2[i])\n",
        "        yy2 = y2[order[1:]].clamp(max=y2[i])\n",
        "\n",
        "        w = (xx2 - xx1 + 1).clamp(min=0)\n",
        "        h = (yy2 - yy1 + 1).clamp(min=0)\n",
        "        inter = w * h\n",
        "\n",
        "        ovr = inter / (areas[i] + areas[order[1:]] - inter)\n",
        "        ids = (ovr <= thres).nonzero().squeeze()\n",
        "        if ids.numel() == 0:\n",
        "            break\n",
        "        order = order[ids+1]\n",
        "    return torch.LongTensor(keep)\n",
        "\n",
        "\n",
        "class DataEncoder():\n",
        "    def __init__(self):\n",
        "        self.anchor_areas = [16*16.0, 32*32.0, 64*64.]  # p3 -> p7\n",
        "        # self.anchor_areas = [32*32.0, 64*64., 128*128.0]\n",
        "        self.aspect_ratios = [2/1., 8/1., 16/1.]\n",
        "        self.anchor_wh = self._get_anchor_wh()\n",
        "\n",
        "    def _get_anchor_wh(self):\n",
        "        anchor_wh = []\n",
        "        for s in self.anchor_areas:\n",
        "            for ar in self.aspect_ratios:\n",
        "                h = math.sqrt(s / ar)\n",
        "                w = ar * h\n",
        "                anchor_wh.append([w, h])\n",
        "        return torch.Tensor(anchor_wh).view(9, 2)\n",
        "\n",
        "    def _get_anchor_boxes(self, input_size):\n",
        "        fm_size = (input_size / pow(2, 2)).ceil()\n",
        "\n",
        "        grid_size = input_size / fm_size\n",
        "        fm_w, fm_h = int(fm_size[0]), int(fm_size[1])\n",
        "        xy = meshgrid(fm_w, fm_h) + 0.5\n",
        "        xy = (xy * grid_size).view(fm_h, fm_w, 1, 2).expand(fm_h,\n",
        "                                                            fm_w, 9, 2)  # (fm_h, fm_w, #anchor, (x, y)\n",
        "        wh = self.anchor_wh.view(1, 1, 9, 2).expand(fm_h, fm_w, 9, 2)\n",
        "        box = torch.cat([xy, wh], 3)  # [x, y, w, h]\n",
        "        return box.view(-1, 4)\n",
        "\n",
        "    def encode(self, boxes, input_size):\n",
        "        '''\n",
        "        Args:\n",
        "            boxes: tensor [#box, [xmin, ymin, xmax, ymax]]\n",
        "            input_size: (W, H)\n",
        "        Returns:\n",
        "            loc_targets: tensor [#anchor(9) * [confidence, xcenter, ycenter, width, height], FH, FW]\n",
        "        '''\n",
        "        fm_size = [math.ceil(i / pow(2, 2)) for i in input_size]\n",
        "        input_size = torch.Tensor(input_size)\n",
        "        anchor_boxes = self._get_anchor_boxes(input_size)\n",
        "\n",
        "\n",
        "        ious = box_iou(xywh2xyxy(anchor_boxes), boxes)\n",
        "        boxes = xyxy2xywh(boxes)\n",
        "\n",
        "        max_ious, max_ids = ious.max(1)\n",
        "        boxes = boxes[max_ids]\n",
        "\n",
        "        loc_xy = (boxes[:, :2] - anchor_boxes[:, :2]) / anchor_boxes[:, 2:]\n",
        "        loc_wh = torch.log(boxes[:, 2:] / anchor_boxes[:, 2:])\n",
        "        loc_targets = torch.cat([loc_xy, loc_wh], 1)\n",
        "\n",
        "        masks = torch.ones(max_ids.size())\n",
        "        masks[max_ious < 0.5] = 0\n",
        "        # masks[(max_ious > 0.3) & (max_ious < 0.7)] = -1\n",
        "\n",
        "        loc_targets = loc_targets.contiguous().view(fm_size[1], fm_size[0], 9, 4)\n",
        "        masks = masks.contiguous().view(fm_size[1], fm_size[0], 9, 1)\n",
        "        return torch.cat((masks, loc_targets), 3).view(fm_size[1], fm_size[0], 9 * 5).permute(2, 0, 1)\n",
        "\n",
        "    def decode(self, loc_preds, input_size, conf_thres=0.5, nms_thres=0.5):\n",
        "        input_size = torch.Tensor(input_size)\n",
        "        anchor_boxes = self._get_anchor_boxes(input_size)\n",
        "        \n",
        "        loc_preds = loc_preds.permute(1, 2, 0).contiguous().view(-1, 5)\n",
        "\n",
        "        conf_preds = loc_preds[:, 0]\n",
        "        loc_xy = F.sigmoid(loc_preds[:, 1:3])\n",
        "        loc_wh = loc_preds[:, 3:]\n",
        "\n",
        "        xy = loc_xy * anchor_boxes[:, 2:] + anchor_boxes[:, :2]\n",
        "        wh = loc_wh.exp() * anchor_boxes[:, 2:]\n",
        "        boxes = torch.cat([xy - wh / 2, xy + wh / 2], 1)\n",
        "\n",
        "        score = conf_preds.sigmoid()\n",
        "        ids = score > conf_thres\n",
        "        ids = ids.nonzero().squeeze()\n",
        "        if len(ids) == 0:\n",
        "            return None\n",
        "        keep = box_nms(boxes[ids], score[ids], thres=nms_thres)\n",
        "        return boxes[ids][keep]\n",
        "\n",
        "import os\n",
        "import json\n",
        "\n",
        "import torch\n",
        "import torch.utils.data as data\n",
        "from PIL import Image\n",
        "\n",
        "\n",
        "class ListDataset(data.Dataset):\n",
        "    def __init__(self, root, transform):\n",
        "        self.root = root\n",
        "        self.transform = transform\n",
        "        self.encoder = DataEncoder()\n",
        "        self.input_size = [300, 200] # W, H\n",
        "\n",
        "        self.fnames = []\n",
        "        self.boxes = []\n",
        "\n",
        "        i = 0\n",
        "        while True:\n",
        "            f = os.path.join(self.root, f'{i}.json')\n",
        "            i += 1\n",
        "            if not os.path.isfile(f):\n",
        "                break\n",
        "            with open(f, 'r') as fp:\n",
        "                info = json.load(fp)\n",
        "            self.fnames.append(info['file'])\n",
        "            box = []\n",
        "            for b in info['boxes']:\n",
        "                xmin = float(b['left'])\n",
        "                ymin = float(b['top'])\n",
        "                xmax = xmin + float(b['width'])\n",
        "                ymax = ymin + float(b['height'])\n",
        "                box.append([xmin, ymin, xmax, ymax])\n",
        "            self.boxes.append(torch.Tensor(box))\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        fname = self.fnames[idx]\n",
        "        img = Image.open(os.path.join(self.root, fname))\n",
        "        if img.mode != 'RGB':\n",
        "            img = img.convert('RGB')\n",
        "\n",
        "        boxes = self.boxes[idx].clone()\n",
        "        img = self.transform(img)\n",
        "        return img, boxes\n",
        "\n",
        "    def collate_fn(self, batch):\n",
        "        imgs = [x[0] for x in batch]\n",
        "        boxes = [x[1] for x in batch]\n",
        "\n",
        "        w, h = self.input_size\n",
        "        n_imgs = len(imgs)\n",
        "        inputs = torch.zeros(n_imgs, 3, h, w)\n",
        "        loc_targets = []\n",
        "        for i in range(n_imgs):\n",
        "            inputs[i] = imgs[i]\n",
        "            loc_target = self.encoder.encode(boxes[i], self.input_size)\n",
        "            loc_targets.append(loc_target)\n",
        "\n",
        "        return inputs, torch.stack(loc_targets)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.fnames)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "u-zS1I4c8yVF",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "import torchvision.transforms as transforms\n",
        "from torch.autograd import Variable\n",
        "from PIL import Image, ImageDraw\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "%matplotlib inline\n",
        "\n",
        "print(\"Encode and Decode test\")\n",
        "\n",
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.485,0.456,0.406), (0.229,0.224,0.225))\n",
        "])\n",
        "testset = ListDataset(root='test', transform=transform)\n",
        "testloader = torch.utils.data.DataLoader(testset, batch_size=1, shuffle=False, num_workers=0, collate_fn=testset.collate_fn)\n",
        "\n",
        "img, loc_targets = next(iter(testloader))\n",
        "boxes = testset.encoder.decode(loc_targets[0], [300, 200])\n",
        "\n",
        "img = Image.open(\"test/0.png\")\n",
        "draw = ImageDraw.Draw(img)\n",
        "for box in boxes:\n",
        "    draw.rectangle(list(box), outline='red')\n",
        "img.show()\n",
        "plt.imshow(img)\n",
        "print(\"sigmoid が xy にかかるからおかしくなるけど、大体あっていることは確認できるはず\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "1_UpWPt3Ar6E",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "from torch.autograd import Variable\n",
        "\n",
        "\n",
        "class Bottleneck(nn.Module):\n",
        "    def __init__(self, in_planes, planes, stride=1):\n",
        "        super().__init__()\n",
        "        self.conv1 = nn.Conv2d(in_planes, planes, kernel_size=1, bias=False)\n",
        "        self.bn1 = nn.BatchNorm2d(planes)\n",
        "        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3,\n",
        "                               stride=stride, padding=2, dilation=2, bias=False)\n",
        "        self.bn2 = nn.BatchNorm2d(planes)\n",
        "        self.conv3 = nn.Conv2d(planes, 2 * planes, kernel_size=1, bias=False)\n",
        "        self.bn3 = nn.BatchNorm2d(2 * planes)\n",
        "\n",
        "        self.downsample = nn.Sequential()\n",
        "        if stride != 1 or in_planes != 2 * planes:\n",
        "            self.downsample = nn.Sequential(\n",
        "                nn.Conv2d(in_planes, 2 * planes, kernel_size=1,\n",
        "                          stride=stride, bias=False),\n",
        "                nn.BatchNorm2d(2 * planes)\n",
        "            )\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = F.relu(self.bn1(self.conv1(x)))\n",
        "        out = F.relu(self.bn2(self.conv2(out)))\n",
        "        out = self.bn3(self.conv3(out))\n",
        "        out += self.downsample(x)\n",
        "        out = F.relu(out)\n",
        "        return out\n",
        "\n",
        "\n",
        "class FeatureExtractNet(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.in_planes = 64\n",
        "\n",
        "        self.conv1 = nn.Conv2d(3, 64, kernel_size=5, stride=1, padding=2, bias=False)\n",
        "        self.bn1 = nn.BatchNorm2d(64)\n",
        "\n",
        "        self.layer1 = self._make_layer(64, 1, stride=1)\n",
        "        self.layer2 = self._make_layer(128, 1, stride=2)\n",
        "        self.layer3 = self._make_layer(256, 1, stride=2)\n",
        "        self.layer4 = self._make_layer(512, 1, stride=2)\n",
        "\n",
        "        self.latlayer1 = nn.Conv2d(2 * 512, 256, kernel_size=1, stride=1, padding=0)\n",
        "        self.latlayer2 = nn.Conv2d(1 * 512, 256, kernel_size=1, stride=1, padding=0)\n",
        "        self.latlayer3 = nn.Conv2d(256, 128, kernel_size=1, stride=1, padding=0)\n",
        "\n",
        "        self.toplayer1 = nn.Conv2d(256, 128, kernel_size=3, stride=1, padding=1)\n",
        "        self.toplayer2 = nn.Conv2d(128, 128, kernel_size=3, stride=1, padding=1)\n",
        "\n",
        "    def _make_layer(self, planes, block, stride):\n",
        "        strides = [stride] + [1] * (block - 1)\n",
        "        layers = []\n",
        "        for stride in strides:\n",
        "            layers.append(Bottleneck(self.in_planes, planes, stride))\n",
        "            self.in_planes = planes * 2\n",
        "        return nn.Sequential(*layers)\n",
        "\n",
        "    def _upsample_add(self, x, y):\n",
        "        _, _, H, W = y.size()\n",
        "        return F.upsample(x, size=(H, W), mode='bilinear') + y\n",
        "\n",
        "    def forward(self, x):\n",
        "        c1 = F.relu(self.bn1(self.conv1(x)))\n",
        "        c1 = F.max_pool2d(c1, kernel_size=3, stride=2, padding=1)\n",
        "        c2 = self.layer1(c1)\n",
        "        c3 = self.layer2(c2)\n",
        "        c4 = self.layer3(c3)\n",
        "        c5 = self.layer4(c4)\n",
        "        p5 = self.latlayer1(c5)\n",
        "        p4 = self._upsample_add(p5, self.latlayer2(c4))\n",
        "        p4 = self.toplayer1(p4)\n",
        "        p3 = self._upsample_add(p4, self.latlayer3(c3))\n",
        "        p3 = self.toplayer2(p3)\n",
        "        return p3"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "8Xq3MxWHLd8G",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "class PositionPredictionHead(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.conv = nn.Conv2d(128, 9 * 5, kernel_size=1, stride=1)\n",
        "        \n",
        "    def forward(self, x):\n",
        "        return self.conv(x)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "vs73wBfSwR12",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "def weighted_binary_cross_entropy(output, target, weight):\n",
        "    loss = weight[1] * (target * torch.log(output)) + \\\n",
        "           weight[0] * ((1 - target) * torch.log(1 - output))\n",
        "\n",
        "    return torch.neg(torch.mean(loss))\n",
        "\n",
        "def loss_positions(loc_preds, loc_targets):\n",
        "    '''\n",
        "    Args:\n",
        "        loc_preds: tensor [#batch, (#anchor * [p, x, y, w, h]), h, w]\n",
        "        loc_targets: tensor [#batch, (#anchor * [p, x, y, w, h]), h, w]\n",
        "    '''\n",
        "\n",
        "    loc_preds = loc_preds.permute(0, 2, 3, 1).contiguous().view(-1, 5)\n",
        "    loc_targets = loc_targets.permute(0, 2, 3, 1).contiguous().view(-1, 5)\n",
        "    \n",
        "    conf_preds = loc_preds[..., 0]\n",
        "    conf_targets = loc_targets[..., 0]\n",
        "    mask = conf_targets > 0.9\n",
        "    \n",
        "    xy_preds = F.sigmoid(loc_preds[..., 1:3])\n",
        "    wh_preds = loc_preds[..., 3:5]\n",
        "    loc_preds = torch.cat([xy_preds, wh_preds], 1)\n",
        "    loc_targets = loc_targets[..., 1:]\n",
        "\n",
        "    loss_conf = weighted_binary_cross_entropy(F.sigmoid(conf_preds), conf_targets, weight=torch.Tensor([1, 9]))\n",
        "    loss_loc = (F.mse_loss(loc_preds, loc_targets, size_average=False, reduce=False) * mask.unsqueeze(1).float()).sum() / mask.data.sum()\n",
        "    return loss_conf + 2 * loss_loc"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Fe-jEaQLI74Y",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "!pip install -U -q PyDrive\n",
        "\n",
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials\n",
        "\n",
        "# 1. Authenticate and create the PyDrive client.\n",
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(gauth)\n",
        "\n",
        "# PyDrive reference:\n",
        "# https://googledrive.github.io/PyDrive/docs/build/html/index.html\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "m1Fvm-ccv37t",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "import torch\n",
        "import torch.optim as optim\n",
        "from torch.autograd import Variable\n",
        "\n",
        "import torchvision.transforms as transforms\n",
        "from itertools import chain\n",
        "import gc\n",
        "\n",
        "gc.collect()\n",
        "\n",
        "CUDA = True\n",
        "\n",
        "\n",
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.485,0.456,0.406), (0.229,0.224,0.225))\n",
        "])\n",
        "trainset = ListDataset(root='train', transform=transform)\n",
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=32, shuffle=True, num_workers=0, collate_fn=trainset.collate_fn)\n",
        "testset = ListDataset(root='test', transform=transform)\n",
        "testloader = torch.utils.data.DataLoader(testset, batch_size=8, shuffle=False, num_workers=0, collate_fn=testset.collate_fn)\n",
        "\n",
        "fnet = FeatureExtractNet()\n",
        "pnet = PositionPredictionHead()\n",
        "\n",
        "if CUDA:\n",
        "    fnet.cuda()\n",
        "    pnet.cuda()\n",
        "\n",
        "optimizer = optim.Adam(chain(fnet.parameters(), pnet.parameters()))\n",
        "\n",
        "\n",
        "def train(epoch):\n",
        "    print(f'\\nEpoch: {epoch}')\n",
        "    fnet.train()\n",
        "    pnet.train()\n",
        "    train_loss = 0\n",
        "    for batch_idx, (inputs, loc_targets) in enumerate(trainloader):\n",
        "        if CUDA:\n",
        "            inputs = inputs.cuda()\n",
        "            loc_targets = loc_targets.cuda()\n",
        "            \n",
        "        inputs = Variable(inputs)\n",
        "        loc_targets = Variable(loc_targets)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        x = fnet(inputs)\n",
        "        loc_preds = pnet(x)\n",
        "        loss = loss_positions(loc_preds, loc_targets)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        train_loss += loss.data[0]\n",
        "    print(f'train_loss: average: {train_loss / (batch_idx + 1)}')\n",
        "\n",
        "def test(epoch):\n",
        "    print('\\nTest')\n",
        "    fnet.eval()\n",
        "    pnet.eval()\n",
        "    test_loss = 0\n",
        "    for batch_idx, (inputs, loc_targets) in enumerate(testloader):\n",
        "        if CUDA:\n",
        "            inputs = inputs.cuda()\n",
        "            loc_targets = loc_targets.cuda()\n",
        "            \n",
        "        inputs = Variable(inputs)\n",
        "        loc_targets = Variable(loc_targets)\n",
        "\n",
        "        x = fnet(inputs)\n",
        "        loc_preds = pnet(x)\n",
        "        loss = loss_positions(loc_preds, loc_targets)\n",
        "        test_loss += loss.data[0]\n",
        "    print('test_loss: average: %.3f' % (test_loss/(batch_idx+1)))\n",
        "\n",
        "start_epoch = 0\n",
        "for epoch in range(start_epoch, start_epoch+50):\n",
        "    train(epoch)\n",
        "    test(epoch)\n",
        "    torch.save(fnet.state_dict(), 'fnet.pth')\n",
        "    torch.save(pnet.state_dict(), 'pnet.pth')\n",
        "    \n",
        "    if (epoch + 1) % 10 == 0:\n",
        "        for filename in ['fnet', 'pnet']:\n",
        "            uploaded = drive.CreateFile({'title': '%s%d.pth' % (filename, epoch + 1)})\n",
        "            uploaded.SetContentFile('%s.pth' % filename)\n",
        "            uploaded.Upload()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "zy2_hWwywMpR",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "import numpy as np\n",
        "import torch\n",
        "import torchvision.transforms as transforms\n",
        "from torch.autograd import Variable\n",
        "from PIL import Image, ImageDraw\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "%matplotlib inline\n",
        "\n",
        "def test(epoch):\n",
        "    transform = transforms.Compose([\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize((0.485,0.456,0.406), (0.229,0.224,0.225))\n",
        "    ])\n",
        "    testset = ListDataset(root='test', transform=transform)\n",
        "    testloader = torch.utils.data.DataLoader(testset, batch_size=16, shuffle=True, num_workers=8, collate_fn=testset.collate_fn)\n",
        "\n",
        "\n",
        "    n = np.random.randint(0, 100)\n",
        "    img = Image.open('test/{}.png'.format(n))\n",
        "    x = transform(img).unsqueeze(0)\n",
        "    x = Variable(x, volatile=True)\n",
        "    fnet = FeatureExtractNet()\n",
        "    pnet = PositionPredictionHead()\n",
        "    fnet.load_state_dict(torch.load(f'fnet{epoch}.pth'))\n",
        "    pnet.load_state_dict(torch.load(f'pnet{epoch}.pth'))\n",
        "\n",
        "    loc_preds = pnet(fnet(x))\n",
        "    boxes = testset.encoder.decode(loc_preds.data.squeeze(0), [300, 200], conf_thres=0.5, nms_thres=0.3)\n",
        "    print(boxes is not None and boxes.size())\n",
        "    print(f'test/{n}.png')\n",
        "    if boxes is not None:\n",
        "        draw = ImageDraw.Draw(img)\n",
        "        for box in boxes:\n",
        "            draw.rectangle(list(box), outline='red')\n",
        "        plt.imshow(img)\n",
        "\n",
        "\n",
        "test(50)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "a-miqQKT7KyH",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}
{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "4Ak4yv3E_CXj"
   },
   "outputs": [],
   "source": [
    "import math\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def meshgrid(x, y):\n",
    "    xx, yy = np.meshgrid(np.arange(0, x), np.arange(0, y))\n",
    "    return np.concatenate([np.expand_dims(xx, 2), np.expand_dims(yy, 2)], axis=2)\n",
    "\n",
    "def xywh2xyxy(boxes):\n",
    "    xy = boxes[..., :2]\n",
    "    wh = boxes[..., 2:]\n",
    "    return np.concatenate([xy - wh / 2, xy + wh / 2], -1)\n",
    "\n",
    "def xyxy2xywh(boxes):\n",
    "    xymin = boxes[..., :2]\n",
    "    xymax = boxes[..., 2:]\n",
    "    return np.concatenate([(xymin + xymax) / 2, xymax - xymin + 1], -1)\n",
    "\n",
    "def box_iou(box1, box2):\n",
    "    x11, y11, x12, y12 = np.split(box1, 4, axis=1)\n",
    "    x21, y21, x22, y22 = np.split(box2, 4, axis=1)\n",
    "    xA = np.maximum(x11, np.transpose(x21))\n",
    "    yA = np.maximum(y11, np.transpose(y21))\n",
    "    xB = np.minimum(x12, np.transpose(x22))\n",
    "    yB = np.minimum(y12, np.transpose(y22))\n",
    "    interArea = np.maximum((xB - xA + 1), 0) * np.maximum((yB - yA + 1), 0)\n",
    "    boxAArea = (x12 - x11 + 1) * (y12 - y11 + 1)\n",
    "    boxBArea = (x22 - x21 + 1) * (y22 - y21 + 1)\n",
    "    iou = interArea / (boxAArea + np.transpose(boxBArea) - interArea)\n",
    "    return iou\n",
    "\n",
    "class DataEncoder():\n",
    "    def __init__(self):\n",
    "        self.anchor_areas = [16.0*16.0, 32*32.0, 64*64.0]\n",
    "        self.aspect_ratios = [2.0, 8.0, 16.0]\n",
    "        self.anchor_wh = self._get_anchor_wh()\n",
    "\n",
    "    def _get_anchor_wh(self):\n",
    "        anchor_wh = []\n",
    "        for s in self.anchor_areas:\n",
    "            for ar in self.aspect_ratios:\n",
    "                h = math.sqrt(s / ar)\n",
    "                w = ar * h\n",
    "                anchor_wh.append([w, h])\n",
    "        return np.array(anchor_wh).reshape(9, 2)\n",
    "    \n",
    "    def _get_anchor_boxes(self, input_size: np.ndarray):\n",
    "        fm_size = np.ceil(input_size / pow(2, 2))\n",
    "        grid_size = input_size / fm_size\n",
    "        fm_w, fm_h = int(fm_size[0]), int(fm_size[1])\n",
    "        xy = meshgrid(fm_w, fm_h) + 0.5\n",
    "        xy = np.tile((xy * grid_size).reshape(fm_h, fm_w, 1, 2), [1, 1, 9, 1])\n",
    "        wh = np.tile(self.anchor_wh.reshape(1, 1, 9, 2), [fm_h, fm_w, 1, 1])\n",
    "        box = np.concatenate((xy, wh), axis=3)\n",
    "        return box.reshape(-1, 4)\n",
    "    \n",
    "    def encode(self, boxes: np.ndarray, input_size: np.ndarray):\n",
    "        '''\n",
    "        Args:\n",
    "            boxes: np.ndarray [#box, [xmin, ymin, xmax, ymax]]\n",
    "            input_size: W, H\n",
    "        Returns:\n",
    "        loc_targets: np.ndarray [FH, FW, #anchor * [confidence, xcenter, ycenter, width, height]]\n",
    "        '''\n",
    "        fm_size = [math.ceil(i / pow(2, 2)) for i in input_size]\n",
    "        anchor_boxes = self._get_anchor_boxes(input_size)\n",
    "        ious = box_iou(xywh2xyxy(anchor_boxes), boxes)\n",
    "        boxes = xyxy2xywh(boxes)\n",
    "        \n",
    "        max_ids = np.argmax(ious, axis=1)\n",
    "        max_ious = np.max(ious, axis=1)\n",
    "        boxes = boxes[max_ids]\n",
    "\n",
    "        loc_xy = (boxes[:, :2] - anchor_boxes[:, :2]) / anchor_boxes[:, 2:]\n",
    "        loc_wh = np.log(boxes[:, 2:] / anchor_boxes[:, 2:])\n",
    "        loc_targets = np.concatenate([loc_xy, loc_wh], axis=1)\n",
    "        \n",
    "        masks = np.ones_like(max_ids)\n",
    "        masks[max_ious < 0.5] = 0\n",
    "        \n",
    "        loc_targets = loc_targets.reshape(fm_size[1], fm_size[0], 9, 4)\n",
    "        masks = masks.reshape(fm_size[1], fm_size[0], 9, 1)\n",
    "        return np.concatenate([masks, loc_targets], axis=3).reshape(fm_size[1], fm_size[0], 9 * 5)\n",
    "\n",
    "    def decode(self, loc_preds, input_size: np.ndarray, conf_thres=0.5):\n",
    "        anchor_boxes = self._get_anchor_boxes(input_size)\n",
    "        loc_preds = loc_preds.reshape(-1, 5)\n",
    "        conf_preds = loc_preds[:, 0]\n",
    "        # TODO: use tensorflow. sigmoid is required.\n",
    "        loc_xy = loc_preds[:, 1:3]\n",
    "        loc_wh = loc_preds[:, 3:]\n",
    "        \n",
    "        xy = loc_xy * anchor_boxes[:, 2:] + anchor_boxes[:, :2]\n",
    "        wh = np.exp(loc_wh) * anchor_boxes[:, 2:]\n",
    "        boxes = np.concatenate([xy - wh / 2, xy + wh / 2], axis=1)\n",
    "        \n",
    "        score = conf_preds # TODO: sigmoid\n",
    "        ids = score > conf_thres\n",
    "        ids = np.nonzero(ids)[0]\n",
    "        return boxes[ids]\n",
    "    \n",
    "def generator(root: str, encoder: DataEncoder):\n",
    "    import os\n",
    "    import json\n",
    "    from PIL import Image\n",
    "    input_size = np.array([300, 200])\n",
    "    fnames = []\n",
    "    boxes = []\n",
    "    texts = []\n",
    "    i = 0\n",
    "    while True:\n",
    "        f = os.path.join(root, f'{i}.json')\n",
    "        i += 1\n",
    "        if not os.path.isfile(f):\n",
    "            break\n",
    "        with open(f, 'r') as fp:\n",
    "            info = json.load(fp)\n",
    "        fnames.append(info['file'])\n",
    "        bbs = []\n",
    "        ts = []\n",
    "        for b in info['boxes']:\n",
    "            xmin = float(b['left'])\n",
    "            ymin = float(b['top'])\n",
    "            xmax = xmin + float(b['width'])\n",
    "            ymax = ymin + float(b['height'])\n",
    "            bbs.append([xmin, ymin, xmax, ymax])\n",
    "            ts.append(bytes(b['text'], 'utf8'))\n",
    "        boxes.append(np.array(bbs))\n",
    "        texts.append(np.array(ts))\n",
    "    def g():\n",
    "        for fname, bbs, ts in zip(fnames, boxes, texts):\n",
    "            img = Image.open(os.path.join(root, fname))\n",
    "            if img.mode != 'RGB':\n",
    "                img = img.convert('RGB')\n",
    "            img = np.array(img)\n",
    "            loc_targets = encoder.encode(bbs, input_size)\n",
    "            yield img, loc_targets, bbs, ts\n",
    "    return g\n",
    "\n",
    "def test():\n",
    "    g = generator('test', DataEncoder())\n",
    "    dataset = tf.data.Dataset.from_generator(g, (tf.float32, tf.float32, tf.float32, tf.string))\n",
    "    dataset = dataset.map(lambda img, locs, bbs, texts: (tf.image.per_image_standardization(img), locs, bbs, texts))\n",
    "    dataset = dataset.padded_batch(10, padded_shapes=([None, None, None], [None, None, None], [None, 5], [None]))\n",
    "    import tensorflow.contrib.eager as tfe\n",
    "    from PIL import Image, ImageDraw\n",
    "    img, loc, bbs, texts = next(tfe.Iterator(dataset))\n",
    "    img = img[0]\n",
    "    loc = loc[0]\n",
    "    decoded_boxes = DataEncoder().decode(loc.numpy(), np.array([300, 200]))\n",
    "    img = Image.fromarray(np.uint8(img.numpy()))\n",
    "    draw = ImageDraw.Draw(img)\n",
    "    for box in decoded_boxes:\n",
    "        draw.rectangle(list(box), outline='red')\n",
    "    img.show()\n",
    "    \n",
    "\n",
    "# test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bottleneck(inputs: tf.Tensor, planes, strides=1, training=False):\n",
    "    in_places = inputs.shape[-1]\n",
    "    x = tf.layers.conv2d(inputs, planes, kernel_size=1, use_bias=False)\n",
    "    x = tf.layers.batch_normalization(x, training=training)\n",
    "    x = tf.nn.relu(x)\n",
    "    x = tf.layers.conv2d(x, planes, kernel_size=3, strides=strides, padding='same', use_bias=False)\n",
    "    x = tf.layers.batch_normalization(x, training=training)\n",
    "    x = tf.nn.relu(x)\n",
    "    x = tf.layers.conv2d(x, 2 * planes, kernel_size=1, use_bias=False)\n",
    "    x = tf.layers.batch_normalization(x, training=training)\n",
    "    if strides != 1 or inputs.shape[-1] != x.shape[-1]:\n",
    "        y = tf.layers.conv2d(inputs, x.shape[-1], kernel_size=1, strides=strides, use_bias=False)\n",
    "        y = tf.layers.batch_normalization(y, training=training)\n",
    "        x += y\n",
    "    return tf.nn.relu(x)\n",
    "\n",
    "def upsampling_add(x, y):\n",
    "    _, h, w, _ = y.shape\n",
    "    return tf.image.resize_bilinear(x, size=(h, w)) + y\n",
    "\n",
    "def feature_extract(inputs: tf.Tensor, training=False):\n",
    "    x = tf.layers.conv2d(inputs, 64, kernel_size=5, strides=1, padding='same', use_bias=False)\n",
    "    x = tf.layers.batch_normalization(x, training=training)\n",
    "    c1 = tf.layers.max_pooling2d(tf.nn.relu(x), pool_size=3, strides=2, padding='same')\n",
    "    c2 = bottleneck(c1, 64, strides=1, training=training)\n",
    "    c3 = bottleneck(c2, 128, strides=2, training=training)\n",
    "    c4 = bottleneck(c3, 256, strides=2, training=training)\n",
    "    c5 = bottleneck(c4, 512, strides=2, training=training)\n",
    "    p5 = tf.layers.conv2d(c5, 256, kernel_size=1, strides=1)\n",
    "    p4 = upsampling_add(p5, tf.layers.conv2d(c4, 256, kernel_size=1, strides=1))\n",
    "    p4 = tf.layers.conv2d(p4, 128, kernel_size=3, strides=1, padding='same')\n",
    "    p3 = upsampling_add(p4, tf.layers.conv2d(c3, 128, kernel_size=1, strides=1))\n",
    "    p3 = tf.layers.conv2d(p3, 128, kernel_size=3, strides=1, padding='same')\n",
    "    return p3\n",
    "\n",
    "def position_prediction_head(fm: tf.Tensor):\n",
    "    return tf.layers.conv2d(fm, 9 * 5, kernel_size=1, strides=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weighted_binary_cross_entropy(output, target, weights):\n",
    "    loss = weights[1] * (target * tf.log(output)) + weights[0] * ((1 - target) * tf.log(1 - output))\n",
    "    return tf.negative(tf.reduce_mean(loss))\n",
    "\n",
    "def loss_positions(loc_preds: tf.Tensor, loc_targets: tf.Tensor):\n",
    "    '''\n",
    "    Args:\n",
    "        loc_preds: [#batch, h, w, (#anchor * [p, x, y, w, h])]\n",
    "        loc_targets: [#batch, h, w, (#anchor * [p, x, y, w, h])]\n",
    "    '''\n",
    "    loc_preds = tf.reshape(loc_preds, (-1, 5))\n",
    "    loc_targets = tf.reshape(loc_targets, (-1, 5))\n",
    "    conf_preds = tf.sigmoid(loc_preds[..., 0])\n",
    "    conf_targets = loc_targets[..., 0]\n",
    "    mask = conf_targets > 0.9\n",
    "    \n",
    "    xy_preds = tf.sigmoid(loc_preds[..., 1:3])\n",
    "    wh_preds = loc_preds[..., 3:5]\n",
    "    loc_preds = tf.concat([xy_preds, wh_preds], axis=1)\n",
    "    loc_targets = loc_targets[..., 1:]\n",
    "    \n",
    "    loss_conf = weighted_binary_cross_entropy(conf_preds, conf_targets, weights=[1, 10])\n",
    "    loss_loc = tf.reduce_sum(tf.losses.mean_squared_error(loc_targets, loc_preds, reduction=tf.losses.Reduction.NONE), axis=1)\n",
    "    loss_loc_mean = tf.reduce_sum(loss_loc * tf.cast(mask, tf.float32)) / tf.reduce_sum(tf.cast(mask, tf.float32))\n",
    "    loss = loss_conf + 2 * loss_loc_mean\n",
    "    return loss_conf + 2 * loss_loc_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using config: {'_model_dir': '/tmp/checkpoint', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 10, '_session_config': None, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7fc8d81e5ef0>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from /tmp/checkpoint/model.ckpt-3\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "tfdbg: caught SIGINT; calling sys.exit(1).\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "1",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[0;31mSystemExit\u001b[0m\u001b[0;31m:\u001b[0m 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/naomichi/repos/src/github.com/agatan/ssocr/venv/lib/python3.6/site-packages/IPython/core/interactiveshell.py:2971: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
      "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "def model_fn(features, labels, mode):\n",
    "    training = mode == tf.estimator.ModeKeys.TRAIN\n",
    "    fm = feature_extract(features, training=training)\n",
    "    loc_preds = position_prediction_head(fm)\n",
    "    if mode == tf.estimator.ModeKeys.PREDICT:\n",
    "        predictions = dict(locations=loc_preds)\n",
    "        return tf.estimator.EstimatorSpec(mode, predictions=predictions)\n",
    "    \n",
    "    loss = loss_positions(loc_preds, labels['box'])\n",
    "    if mode == tf.estimator.ModeKeys.EVAL:\n",
    "        return tf.estimator.EstimatorSpec(mode, loss=loss, eval_metric_ops=dict())\n",
    "    \n",
    "    optimizer = tf.train.AdamOptimizer()\n",
    "    update_ops = tf.get_collection(tf.GraphKeys.UPDATE_OPS)\n",
    "    with tf.control_dependencies(update_ops):\n",
    "        train_op = optimizer.minimize(loss, global_step=tf.train.get_global_step())\n",
    "    return tf.estimator.EstimatorSpec(mode=mode, loss=loss, train_op=train_op)\n",
    "\n",
    "def input_fn(root):\n",
    "    g = generator(root, DataEncoder())\n",
    "    dataset = tf.data.Dataset.from_generator(g, (tf.float32, tf.float32, tf.float32, tf.string))\n",
    "    def mapper(img, locs, bbs, texts):\n",
    "        return (img, dict(box=locs, bbs=bbs, texts=texts))\n",
    "    dataset = dataset.map(lambda img, locs, bbs, texts: (tf.image.per_image_standardization(img), locs, bbs, texts))\n",
    "    dataset = dataset.padded_batch(32, padded_shapes=([200, 300, 3], [None, None, None], [None, 5], [None]))\n",
    "    dataset = dataset.map(mapper)\n",
    "    \n",
    "    return dataset\n",
    "\n",
    "def main():\n",
    "    from tensorflow.python import debug as tf_debug\n",
    "\n",
    "    # Create a LocalCLIDebugHook and use it as a monitor when calling fit().\n",
    "    hooks = [tf_debug.LocalCLIDebugHook()]\n",
    "    config = tf.estimator.RunConfig(\n",
    "        model_dir='/tmp/checkpoint',\n",
    "        save_checkpoints_secs=10,\n",
    "    )\n",
    "    estimator = tf.estimator.Estimator(model_fn=model_fn, config=config)\n",
    "    \n",
    "    def train_input_fn():\n",
    "        return input_fn('test')\n",
    "    \n",
    "    def test_input_fn():\n",
    "        return input_fn('test')\n",
    "    \n",
    "    estimator.train(train_input_fn, hooks=hooks)\n",
    "    \n",
    "    experiment = tf.contrib.learn.Experiment(estimator, train_input_fn, test_input_fn)\n",
    "    experiment.train_and_evaluate()\n",
    "    \n",
    "main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "zy2_hWwywMpR"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "from torch.autograd import Variable\n",
    "from PIL import Image, ImageDraw\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "def test(epoch):\n",
    "    transform = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.485,0.456,0.406), (0.229,0.224,0.225))\n",
    "    ])\n",
    "    testset = ListDataset(root='test', transform=transform)\n",
    "    testloader = torch.utils.data.DataLoader(testset, batch_size=16, shuffle=True, num_workers=8, collate_fn=testset.collate_fn)\n",
    "\n",
    "\n",
    "    n = np.random.randint(0, 100)\n",
    "    img = Image.open('test/{}.png'.format(n))\n",
    "    x = transform(img).unsqueeze(0)\n",
    "    x = Variable(x, volatile=True)\n",
    "    fnet = FeatureExtractNet()\n",
    "    pnet = PositionPredictionHead()\n",
    "    fnet.load_state_dict(torch.load(f'fnet{epoch}.pth'))\n",
    "    pnet.load_state_dict(torch.load(f'pnet{epoch}.pth'))\n",
    "\n",
    "    loc_preds = pnet(fnet(x))\n",
    "    boxes = testset.encoder.decode(loc_preds.data.squeeze(0), [300, 200], conf_thres=0.5, nms_thres=0.3)\n",
    "    print(boxes is not None and boxes.size())\n",
    "    print(f'test/{n}.png')\n",
    "    if boxes is not None:\n",
    "        draw = ImageDraw.Draw(img)\n",
    "        for box in boxes:\n",
    "            draw.rectangle(list(box), outline='red')\n",
    "        plt.imshow(img)\n",
    "\n",
    "\n",
    "test(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "a-miqQKT7KyH"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "default_view": {},
   "name": "Untitled0.ipynb",
   "private_outputs": true,
   "provenance": [],
   "version": "0.3.2",
   "views": {}
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
